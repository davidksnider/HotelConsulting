---
title: "HotelsFinalAnalysis"
author: "Walker Burgin, Tara Ghorpadkar, David Snider, Sid Vanam"
date: "7/27/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,include=F}
library(tidyverse)
library(countrycode)
library(rvest)
library(dplyr)
library(tidyr)
library(xtable)
library(modelr)
library(broom)
library(class)
library(lubridate)
library(pracma)
library(class)

df = read_csv("hotel_booking.csv")
k_df = read_csv("k_df.csv")
```

# Question 2: Predicting  Cancellation

Analysis of significant variables:
```{r, include=F}
library(MASS)
```

```{r, echo=F}
leadgraph = df %>% 
  group_by(as.logical(is_canceled)) %>%
  summarize(avg_lead_time = mean(lead_time)) %>% 
  ungroup() %>%
  rename(value=avg_lead_time)
leadgraph$key=rep("Average Lead Time", 2)

prevgraph = df %>%
  group_by(as.logical(is_canceled)) %>%
  summarize(avg_prev_canc = mean(previous_cancellations)) %>% 
  ungroup() %>%
  rename(value=avg_prev_canc)
prevgraph$key=rep("Average Previous Cancellations", 2)

prevuncancgraph = df %>%
  group_by(as.logical(is_canceled)) %>%
  summarize(avg_prev_uncanc = mean(previous_bookings_not_canceled)) %>% 
  ungroup() %>%
  rename(value=avg_prev_uncanc)
prevuncancgraph$key=rep("Average Previous Bookings Not Canceled", 2)

adrgraph = df %>%
  group_by(as.logical(is_canceled)) %>%
  summarize(avg_adr = mean(adr)) %>% 
  ungroup() %>%
  rename(value=avg_adr)
adrgraph$key=rep("Average ADR", 2)

fullgraph = bind_rows(leadgraph, prevgraph, prevuncancgraph, adrgraph)

ggplot(fullgraph, aes(x=`as.logical(is_canceled)`, y=value)) + 
  geom_col() + 
  facet_wrap(~key, scales = "free")
  
hotelgraph = df %>%
  group_by(hotel) %>%
  summarize(
    n=n(),
    num_canceled = sum(is_canceled),
    prop_canceled = mean(is_canceled)
  ) %>%
  ungroup() %>%
  rename(value=hotel)
hotelgraph$key=rep("Hotel", 2)

repeatgraph = df %>%
  group_by(as.logical(is_repeated_guest)) %>%
  summarize(
    n=n(),
    num_canceled = sum(is_canceled),
    prop_canceled = mean(is_canceled)
  ) %>%
  ungroup() %>%
  rename(value=`as.logical(is_repeated_guest)`)
repeatgraph$key=rep("Is Repeated Guest?", 2)
repeatgraph$value=as.character(repeatgraph$value)

fullgraph2 = bind_rows(hotelgraph, repeatgraph)

ggplot(fullgraph2, aes(x=value, y=prop_canceled)) + 
  geom_col() + 
  facet_wrap(~key, scales="free")
detach("package:MASS", unload = TRUE)
```

```{r, results="asis", echo=F}
pvals = c()

pvals = c(
  t.test(df$lead_time~as.logical(df$is_canceled))$p.value[[1]],
  t.test(df$previous_cancellations~as.logical(df$is_canceled))$p.value[[1]],
  t.test(df$previous_bookings_not_canceled~as.logical(df$is_canceled))$p.value[[1]],
  t.test(df$adr~as.logical(df$is_canceled))$p.value[[1]],
  (prop.test(x=hotelgraph$num_canceled, 
             n=hotelgraph$n,
             p=NULL,
             alternative = "two.sided",
             correct=TRUE))$p.value[[1]],
  (prop.test(x=repeatgraph$num_canceled, 
             n=repeatgraph$n,
             p=NULL,
             alternative = "two.sided",
             correct=TRUE))$p.value[[1]]
)
pvals=formatC(x=pvals, format="e", digits=2)

vars = c("Average Lead Time",
         "Average Previous Cancellations",
         "Average Previous Bookings Not Canceled",
         "Average ADR",
         "Hotel",
         "Is Repeated Customer?")

pvaltable = data.frame(Variables = vars, "P values" = pvals)
pvaltable$P.values = as.character(pvaltable$P.values)
to_print = pvaltable %>% 
  xtable(align="ccc")
print(to_print, 
      "html", 
      include.rownames=F,
      html.table.attributes="align='center',
                             rules='rows',
                             width=50%,
                             frame='hsides',
                             border-spacing=5px"
      )
```

Building logistic, k-NN, and RandomTrees models

Data cleaning:

```{r, echo=F}
library(MASS)
df_log = df %>%
  dplyr::select(hotel,
         is_canceled,
         lead_time,
         previous_cancellations,
         previous_bookings_not_canceled,
         adr,
         is_repeated_guest
         ) %>% mutate(id=row_number())

set.seed(216)
df_train=df_log %>% 
  sample_frac(0.80)
df_test=anti_join(df_log, df_train, by='id')
df_train= df_train %>%
  subset(select = -id)
df_test= df_test %>%
  subset(select= -id)
```

Model 1: Logistic

```{r, include=F}
model1 = glm(
  is_canceled~., 
  family="binomial",
  data=df_train)

options("scipen"=100, "digits"=4)
summary(model1)

df_test = df_test %>% add_predictions(
  model1,
  var="predicted_canc1") %>%
  mutate(predicted_canc1 = ifelse(predicted_canc1 > 0.5,1,0))
```

Model 2: Stepwise logistic

```{r}
model2 = stepAIC(model1)

df_test = df_test %>% add_predictions(
  model2,
  var="predicted_canc2") %>%
  mutate(predicted_canc2 = ifelse(predicted_canc2 > 0.5,1,0))
```

Model 3: Logistic with twofold interaction

```{r}
model3 = glm(
  is_canceled~.^2, 
  family="binomial",
  data=df_train)
tidy(model3)[,c("term", "estimate", "p.value")]

df_test = df_test %>% add_predictions(
  model3,
  var="predicted_canc3") %>%
  mutate(predicted_canc3 = ifelse(predicted_canc3 > 0.5,1,0))
```

Model4: k-NN, k=5

```{r}
#standardize dataset
standardize = function(vector) {
  return(sd(vector)*vector + 
           mean(vector)
              )
}

df_knn = df_test %>%
  mutate(
    previous_cancellations=standardize(previous_cancellations),
    previous_bookings_not_canceled=standardize(previous_bookings_not_canceled),
    hotel=ifelse(hotel=="Resort Hotel", 1, 0),
    hotel=standardize(hotel),
    lead_time=standardize(lead_time),
    adr=standardize(adr)
    ) %>% 
  mutate(predicted_canc4=knn(
    train=dplyr::select(
      df_train,
      lead_time,
      adr,
      previous_cancellations
      ),
    test=dplyr::select(
      df_test,
      lead_time,
      adr,
      previous_cancellations
    ),
    cl=
      factor(
      df_train$is_canceled,
      levels=c(0,1),
      labels=c("0","1")
    ),
    k=5)
  ) %>%
  dplyr::select(predicted_canc4)

df_test = bind_cols(df_test, df_knn) %>%
  mutate(predicted_canc4 = as.integer(predicted_canc4)-1)
```

Metrics:

```{r, results="asis"}
#input df_test$predicted_canc1, or 2, etc.
sensitivity = function(predicted_canc) {
  return(
    sum(df_test$is_canceled & predicted_canc) /
      sum(df_test$is_canceled)
  )
}

specificity = function(predicted_canc) {
  return(
    sum(!df_test$is_canceled & !predicted_canc) /
      sum(!df_test$is_canceled)
  )
}

accuracy = function(predicted_canc) {
  (
  sum(df_test$is_canceled & predicted_canc) + 
    sum(!df_test$is_canceled & !predicted_canc)
  ) / nrow(df_test)
}

metrics_table = tribble(
  ~Model, ~sensitivity, ~specificity, ~accuracy,
  1, sensitivity(df_test$predicted_canc1), specificity(df_test$predicted_canc1), accuracy(df_test$predicted_canc1),
  2, sensitivity(df_test$predicted_canc2), specificity(df_test$predicted_canc2), accuracy(df_test$predicted_canc2),
  3, sensitivity(df_test$predicted_canc3), specificity(df_test$predicted_canc3), accuracy(df_test$predicted_canc3),
  4, sensitivity(df_test$predicted_canc4), specificity(df_test$predicted_canc4), accuracy(df_test$predicted_canc4)
)

to_print1 = metrics_table %>% 
  xtable(align="ccccc")
print(to_print1, 
      "html", 
      html.table.attributes="align='center',
                             rules='rows',
                             width=50%,
                             frame='hsides',
                             border-spacing=5px"
)
detach("package:MASS", unload = TRUE)

df %>% filter(is_canceled==1)
```

Formulas
```{r}
standardize = function(vector) {
  z = (vector-mean(vector))/sd(vector)
  return(z)
}

#divides correct prediction by total predictions
accuracy = function(x) {
  sum(diag(x)/(sum(rowSums(x))))
}
```


Created file, so no longer need to run this code. Storing it here with eval=F.
```{r, eval=F}
set.seed(216)
ran = sample(1:nrow(df), 0.8 * nrow(df))
df_hotel_binary = df %>% mutate(hotel = ifelse(hotel == "Resort Hotel", 1, 0))
df_norm = as.data.frame(lapply(df_hotel_binary[, c("previous_cancellations", "previous_bookings_not_canceled", "lead_time", "adr", "hotel")], standardize)) 
#subset = df[sample(x=nrow(df), size=10000), ]
df_train = df_norm[ran, ] #%>% cbind(., )
df_test = df_norm[-ran, ]
df_target_category = df[ran, "is_canceled"] %>% pull(is_canceled)
df_test_category = df[-ran, "is_canceled"] %>% pull(is_canceled)
acc = vector("double", 100)
sens = vector("double", 100)
spec = vector("double", 100)
options(width = 80)
for (k in 1:100){
  knn_output = knn(df_train, df_test, cl=df_target_category, k=k)
  confusion_matrix = table(knn_output, df_test_category)
  acc[[k]]= accuracy(confusion_matrix)
  sens[[k]]= confusion_matrix[2,2] / sum(confusion_matrix[,2])
  spec[[k]]= confusion_matrix[1,1] / sum(confusion_matrix[,1])
}
k = as.integer(1:100)
k_df = data.frame(
  k,
  acc,
  sens,
  spec
)
```


Use cross validation to find accuracy for each k-value on that subset (maybe a range of k from 1 to 100)


>>>>>>> f4c05e7aaa5482a2a3ba99b8957c5c7d8af73d03
# Next Steps:

- Visualize Metrics as K increases for KNN
```{r}
k_df_plot = k_df %>% 
  rename(
    "Accuracy"="acc",
    "Sensitivity"="sens",
    "Specificity"="spec"
  ) %>%
  gather(
    "Accuracy":"Specificity", 
    key="Metric", 
    value="Value"
    )
ggplot(k_df_plot) + 
  geom_line(aes(x=k, y=Value, color=Metric)) + 
  ggtitle("Performance of k-NN model by k value")
```

- Calculate F1 score for both Logistic Regression and KNN + Visualize
- Make a RF model w/ accomopanying metrics


Make sure there aren't too many NA's (check)
```{r}
city_hotels2 = df %>% filter(hotel == "City Hotel", is_canceled == 0) %>% dplyr::select(arrival_date_year, arrival_date_month, arrival_date_day_of_month,stays_in_week_nights, stays_in_weekend_nights, adr) %>% mutate(length_of_stay = stays_in_week_nights + stays_in_weekend_nights) %>% arrange(arrival_date_year, arrival_date_month, arrival_date_day_of_month)

city_hotels2$arrival_date_month = as.integer(factor(city_hotels2$arrival_date_month, levels = month.name))

city_hotels2 = city_hotels2 %>% dplyr::select(arrival_date_year, arrival_date_month, arrival_date_day_of_month, length_of_stay, adr) %>% unite("arrival_date", c("arrival_date_year", "arrival_date_month", "arrival_date_day_of_month"), sep = "/") %>% filter(adr != 0.00)

city_hotels2$arrival_date <- as.Date(city_hotels2$arrival_date)
city_hotels2 = city_hotels2 %>% arrange(arrival_date)  %>% group_by(arrival_date) %>% summarise(avg_length_of_stay = mean(length_of_stay), avg_adr = mean(adr))

model_data_city = city_hotels2
start_date = as.Date("2015-07-01")
model_data_city$arrival_date <- as.numeric(difftime(model_data_city$arrival_date, start_date, unit = "days"))
NumDays.city <- model_data_city$arrival_date
```


```{r, results="asis"}
q1table = model_data_city %>% 
  head(4) %>%
  select(-avg_length_of_stay) %>%
  mutate(arrival_date = as.integer(arrival_date)) %>%
  xtable(
    align="ccc", 
    type="html")
print(q1table, 
      "html", 
      include.rownames=FALSE,
      html.table.attributes="align='center',
                             rules='rows',
                             width=50%,
                             frame='hsides',
                             border-spacing=5px")
```

Use cross validation to find accuracy for each k-value on that subset (maybe a range of k from 1 to 100)

# Next Steps:

- Visualize Metrics as K increases for KNN
- Calculate F1 score for both Logistic Regression and KNN + Visualize
- Make a RF model w/ accomopanying metrics

Make sure there aren't too many NA's (check)
