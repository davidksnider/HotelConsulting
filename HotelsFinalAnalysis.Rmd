---
title: "HotelsFinalAnalysis"
author: "Walker Burgin, Tara Ghorpadkar, David Snider, Sid Vanam"
date: "7/27/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,include=F}
library(tidyverse)
library(countrycode)
library(rvest)
library(dplyr)
library(tidyr)
library(xtable)
library(modelr)
library(broom)
library(class)
library(lubridate)
library(pracma)
library(class)

df = read_csv("hotel_booking.csv")
k_df = read_csv("k_df.csv")
```

# Introduction

Our group used a hotel booking dataset from two hotels in Portugal to answer questions relevant to the travel industry. Each row of data contains several different variables, such as hotel type that was booked by the specific customer, country of origin, and reservation status. Firstly, we asked whether we could predict future room rates with confidence. Such a tool would be useful for travel agencies, hotels and customers. Although hotels can provide rates only for a finite number of months, a model that predicts future rates may enable travel agencies to book vacations further into the future. Using such a model, travel agencies would provide more utility to both customers and clients. Customers could have more booking options, while hotels could increase ease of transaction. Hotels could also understand demand earlier, and thus prepare their budget accordingly.

Secondly, we asked which model best predicts cancellation. In our dataset, about one third (0.37) of bookings ended up getting canceled. Hotels that can predict cancellation can modify operations accordingly. For example, when asking if a customer wishes to be put on a waitlist, the booker can inform the customer of how many clients they predict to cancel, and as such whether the hotel thinks the customer will get a room. Alternatively, a hotel could double book a proportion of rooms that are predicted to be canceled, a risk, but perhaps a profitable one. 


# Data

```{r, include=F}
#data cleaning
cleaned1 = df %>% 
  filter(is_canceled == 0) %>% 
  dplyr::select(
    hotel,
    arrival_date_year, 
    arrival_date_month, 
    arrival_date_day_of_month,
    stays_in_week_nights, 
    stays_in_weekend_nights, 
    adr) %>% 
  mutate(length_of_stay = stays_in_week_nights + stays_in_weekend_nights) %>% 
  arrange(
    arrival_date_year, 
    arrival_date_month, 
    arrival_date_day_of_month) %>%
  dplyr::select(
    arrival_date_year, 
    arrival_date_month, 
    arrival_date_day_of_month, 
    length_of_stay, 
    adr, 
    hotel) 
cleaned1$arrival_date_month = as.integer(
  factor(cleaned1$arrival_date_month, 
         levels = month.name))
cleaned1 = cleaned1 %>%
  unite("arrival_date", 
        c("arrival_date_year", 
          "arrival_date_month", 
          "arrival_date_day_of_month"), 
        sep = "/") %>% 
  filter(adr != 0.00)

city_hotels2 = cleaned1 %>% 
  filter(hotel == "City Hotel")
resort_hotels2 = cleaned1 %>%
  filter(hotel == "Resort Hotel")

# city_hotels2 = city_hotels2 %>% 
#   dplyr::select(
#     arrival_date_year, 
#     arrival_date_month, 
#     arrival_date_day_of_month, 
#     length_of_stay, 
#     adr) %>% 
#   unite("arrival_date", 
#         c("arrival_date_year", 
#           "arrival_date_month", 
#           "arrival_date_day_of_month"), 
#         sep = "/") %>% 
#   filter(adr != 0.00)

city_hotels2$arrival_date <- as.Date(city_hotels2$arrival_date)
city_hotels2 = city_hotels2 %>% 
  arrange(arrival_date) %>% 
  group_by(arrival_date) %>% 
  summarise(
    avg_adr = mean(adr)
    )
resort_hotels2$arrival_date <- as.Date(resort_hotels2$arrival_date)
resort_hotels2 = resort_hotels2 %>% 
  arrange(arrival_date) %>% 
  group_by(arrival_date) %>% 
  summarise(
    avg_adr = mean(adr)
    )

model_data_city = city_hotels2
start_date = as.Date("2015-07-01")
model_data_city$arrival_date <- as.numeric(
  difftime(model_data_city$arrival_date, 
           start_date, 
           unit = "days"))
NumDays.city <- model_data_city$arrival_date

model_data_resort = resort_hotels2
model_data_resort$arrival_date <- as.numeric(
  difftime(model_data_resort$arrival_date, 
           start_date, 
           unit = "days"))
NumDays.resort <- model_data_resort$arrival_date
```

*data goes here*

Data table for Q1: 

```{r, echo=F, results="asis"}
#Table for Q1
q1table = model_data_city %>% 
  head(4) %>%
  mutate(arrival_date = as.integer(arrival_date)) %>%
  xtable(
    align=c("c","c","c"),
    type="html")
print(q1table, 
      "html", 
      include.rownames=FALSE,
      html.table.attributes="align='center',
                             rules='rows',
                             width=50%,
                             frame='hsides',
                             border-spacing=5px")
```

# Results

## Question 1: Can we predict future room rates with confidence?

```{r, echo=F}
xc <- cos(2*pi*model_data_city$arrival_date/365.25)
xs <- sin(2*pi*model_data_city$arrival_date/365.25)
fit.lm <- lm(avg_adr ~ xc + xs + arrival_date, data = model_data_city)
model_data_city$pred1 <- predict(fit.lm, model_data_city)
model.func = function(day){
  return(
    fit.lm$coefficients[[1]] + fit.lm$coefficients[[2]]*cos(2*pi*day/365.25) + fit.lm$coefficients[[3]]*sin(2*pi*day/365.25) + fit.lm$coefficients[[4]]*day
  )
}
p1 <- ggplot() + geom_point(data = model_data_city, aes(x = arrival_date, y = avg_adr)) + geom_hline(aes(yintercept=0))
p1.trend = p1  + 
  geom_line(data = model_data_city, aes(x = arrival_date, y = pred1), color="red", size = 2)
new = data.frame(arrival_date=793:1577)
model_data_city = bind_rows(model_data_city, new)
model_data_city$pred <- model.func(model_data_city$arrival_date)
p1.trend + geom_line(data = model_data_city, aes(x = arrival_date, y = pred)) + geom_vline(xintercept = 792)
```

```{r, echo=F}
xc <- cos(2*pi*model_data_resort$arrival_date/365.25)
xs <- sin(2*pi*model_data_resort$arrival_date/365.25)
fit.lm <- lm(avg_adr ~ xc + xs + arrival_date, data = model_data_resort)
model_data_resort$pred1 <- predict(fit.lm, model_data_resort)
p2 <- ggplot() + geom_point(data =model_data_resort, aes(x = arrival_date, y = avg_adr)) + geom_hline(aes(yintercept=0))
p2.trend = p2  + 
  geom_line(data = model_data_resort, aes(x = arrival_date, y = pred1), color="red", size = 2)
new = data.frame(arrival_date=793:1577)
model_data_resort = bind_rows(model_data_resort, new)
model_data_resort$pred <- model.func(model_data_resort$arrival_date)
p2.trend + geom_line(data = model_data_resort, aes(x = arrival_date, y = pred)) + geom_vline(xintercept = 792)
```



## Question 2: Which model best predicts cancellation?

### Analysis of significant variables:

To determine which variables we should use in our models, we started by identifying the variables that had a significant relationship with cancellation. Here are graphs showing the significant variables' relationship with cancellation: 

```{r, echo=F, figures-side, fig.show="hold", out.width="50%"}
leadgraph = df %>% 
  group_by(as.logical(is_canceled)) %>%
  summarize(avg_lead_time = mean(lead_time)) %>% 
  ungroup() %>%
  rename(value=avg_lead_time)
leadgraph$key=rep("Lead Time", 2)

prevgraph = df %>%
  group_by(as.logical(is_canceled)) %>%
  summarize(avg_prev_canc = mean(previous_cancellations)) %>% 
  ungroup() %>%
  rename(value=avg_prev_canc)
prevgraph$key=rep("Previous Cancellations", 2)

prevuncancgraph = df %>%
  group_by(as.logical(is_canceled)) %>%
  summarize(avg_prev_uncanc = mean(previous_bookings_not_canceled)) %>% 
  ungroup() %>%
  rename(value=avg_prev_uncanc)
prevuncancgraph$key=rep("Previous Bookings Not Canceled", 2)

adrgraph = df %>%
  group_by(as.logical(is_canceled)) %>%
  summarize(avg_adr = mean(adr)) %>% 
  ungroup() %>%
  rename(value=avg_adr)
adrgraph$key=rep("ADR", 2)

fullgraph = bind_rows(leadgraph, prevgraph, prevuncancgraph, adrgraph)

ggplot(fullgraph, aes(x=`as.logical(is_canceled)`, y=value)) + 
  geom_col(fill="slateblue") + 
  facet_wrap(~key, scales = "free") + 
  xlab("Is Canceled?") + 
  ylab("Mean Value")
  
hotelgraph = df %>%
  group_by(hotel) %>%
  summarize(
    n=n(),
    num_canceled = sum(is_canceled),
    prop_canceled = mean(is_canceled)
  ) %>%
  ungroup() %>%
  rename(value=hotel)
hotelgraph$key=rep("Hotel", 2)

repeatgraph = df %>%
  group_by(as.logical(is_repeated_guest)) %>%
  summarize(
    n=n(),
    num_canceled = sum(is_canceled),
    prop_canceled = mean(is_canceled)
  ) %>%
  ungroup() %>%
  rename(value=`as.logical(is_repeated_guest)`)
repeatgraph$key=rep("Is Repeated Guest?", 2)
repeatgraph$value=as.character(repeatgraph$value)

fullgraph2 = bind_rows(hotelgraph, repeatgraph)

ggplot(fullgraph2, aes(x=value, y=prop_canceled)) + 
  geom_col(fill="slateblue") + 
  facet_wrap(~key, scales="free") + 
  xlab("Value") + 
  ylab("Proportion Canceled")
```

Below are the P values for the above relationships. The P values for the first 4 variables were calculated using a T-test. The P values for the last 2 were calculated using a two proportion Z-test.

```{r, results="asis", echo=F}
pvals = c()

pvals = c(
  t.test(df$lead_time~as.logical(df$is_canceled))$p.value[[1]],
  t.test(df$previous_cancellations~as.logical(df$is_canceled))$p.value[[1]],
  t.test(df$previous_bookings_not_canceled~as.logical(df$is_canceled))$p.value[[1]],
  t.test(df$adr~as.logical(df$is_canceled))$p.value[[1]],
  (prop.test(x=hotelgraph$num_canceled, 
             n=hotelgraph$n,
             p=NULL,
             alternative = "two.sided",
             correct=TRUE))$p.value[[1]],
  (prop.test(x=repeatgraph$num_canceled, 
             n=repeatgraph$n,
             p=NULL,
             alternative = "two.sided",
             correct=TRUE))$p.value[[1]]
)
pvals=formatC(x=pvals, format="e", digits=2)

vars = c("Average Lead Time",
         "Average Previous Cancellations",
         "Average Previous Bookings Not Canceled",
         "Average ADR",
         "Hotel",
         "Is Repeated Customer?")

pvaltable = data.frame(Variables = vars, "P values" = pvals)
pvaltable$P.values = as.character(pvaltable$P.values)
to_print = pvaltable %>% 
  xtable(align="ccc")
print(to_print, 
      "html", 
      include.rownames=F,
      html.table.attributes="align='center',
                             rules='rows',
                             width=50%,
                             frame='hsides',
                             border-spacing=5px"
      )
```

### Model Selection: 

Using the significant variables, we created multiple predictive models: logistic, step-wise logistic, logistic with two-fold interaction, k-NN, and RandomForest. 

```{r, include=F}
#Data cleaning
library(MASS)
df_log = df %>%
  dplyr::select(hotel,
         is_canceled,
         lead_time,
         previous_cancellations,
         previous_bookings_not_canceled,
         adr,
         is_repeated_guest
         ) %>% mutate(id=row_number())

set.seed(216)
df_train=df_log %>% 
  sample_frac(0.80)
df_test=anti_join(df_log, df_train, by='id')
df_train= df_train %>%
  subset(select = -id)
df_test= df_test %>%
  subset(select= -id)
```

```{r, include=F}
#Model 1: Logistic
model1 = glm(
  is_canceled~., 
  family="binomial",
  data=df_train)

options("scipen"=100, "digits"=4)
summary(model1)

df_test = df_test %>% add_predictions(
  model1,
  var="predicted_canc1") %>%
  mutate(predicted_canc1 = ifelse(predicted_canc1 > 0.5,1,0))
```

To provide an example of one of our models, here is a table of coefficients for the simple logistic model:

```{r, results="asis", echo=F}
log_table = tidy(model1)[,c("term", "estimate", "p.value")] %>%
  rename(Term="term",
         Estimate="estimate",
         P.value="p.value") %>%
  mutate(Estimate=format(round(Estimate, 4), nsmall=4),
         P.value=formatC(P.value, format="e", digits = 3))

to_print_log_mod = log_table %>% 
  xtable(align="cccc")
print(to_print_log_mod, 
      "html", 
      include.rownames=F,
      html.table.attributes="align='center',
                             rules='rows',
                             width=50%,
                             frame='hsides',
                             border-spacing=5px"
)
```

```{r, include=F, eval=F}
#Model 2: Stepwise logistic
model2 = stepAIC(model1)

df_test = df_test %>% add_predictions(
  model2,
  var="predicted_canc2") %>%
  mutate(predicted_canc2 = ifelse(predicted_canc2 > 0.5,1,0))
```

```{r, include=F, eval=F}
#Model 3: Logistic with twofold interaction
model3 = glm(
  is_canceled~.^2, 
  family="binomial",
  data=df_train)
tidy(model3)[,c("term", "estimate", "p.value")] #make tables using these tibbles?

df_test = df_test %>% add_predictions(
  model3,
  var="predicted_canc3") %>%
  mutate(predicted_canc3 = ifelse(predicted_canc3 > 0.5,1,0))
```

```{r, eval=F, include=F}
#Model4: k-NN, k=11

#standardize dataset
standardize = function(vector) {
  return(sd(vector)*vector + 
           mean(vector)
              )
}

df_knn = df_test %>%
  mutate(
    previous_cancellations=standardize(previous_cancellations),
    previous_bookings_not_canceled=standardize(previous_bookings_not_canceled),
    hotel=ifelse(hotel=="Resort Hotel", 1, 0),
    hotel=standardize(hotel),
    lead_time=standardize(lead_time),
    adr=standardize(adr)
    ) %>% 
  mutate(predicted_canc4=knn(
    train=dplyr::select(
      df_train,
      lead_time,
      adr,
      previous_cancellations
      ),
    test=dplyr::select(
      df_test,
      lead_time,
      adr,
      previous_cancellations
    ),
    cl=
      factor(
      df_train$is_canceled,
      levels=c(0,1),
      labels=c("0","1")
    ),
    k=11)
  ) %>%
  dplyr::select(predicted_canc4)

df_test = bind_cols(df_test, df_knn) %>%
  mutate(predicted_canc4 = as.integer(predicted_canc4)-1)
```

**Choosing k for k-NN**

To determine which k value we should use for our k-NN model, we analyzed changes in accuracy, sensitivity, and specificity over time. In the context of our situation, it is more important that hotels correctly classify those who did not cancel, because we want to minimize the hassle from overbooking rooms that weren't actually canceled. However, we still want to maintain accuracy. Thus, we care more about accuracy and specificity than sensitivity. Accordingly, we chose k=11, because it maximizes accuracy$\times$specificity. Below is a visualization of this analysis.

```{r, echo=F}
k_df_plot = k_df %>% 
  rename(
    "Accuracy"="acc",
    "Sensitivity"="sens",
    "Specificity"="spec"
  ) %>%
  gather(
    "Accuracy":"Specificity", 
    key="Metric", 
    value="Value"
    )
ggplot(k_df_plot) + 
  geom_line(aes(x=k, y=Value, color=Metric)) + 
  ggtitle("Performance of k-NN model by k value") + 
  geom_vline(xintercept=11, color="black", size=0.5)
```

### Model Performance

The logistic models performed the same in terms of accuracy, sensitivity, and specificity, so we consider only the simple logistic model here. Our models are:

**Model 1:** Logistic

**Model 2:** k-NN, with k=11

**Model 3:** RandomForest, with ntree=**fill in this blank**

Below are metrics of our models' performance. 

```{r, results="asis", echo=F}
#input df_test$predicted_canc1, or 2, etc.
sensitivity = function(predicted_canc) {
  return(
    sum(df_test$is_canceled & predicted_canc) /
      sum(df_test$is_canceled)
  )
}

specificity = function(predicted_canc) {
  return(
    sum(!df_test$is_canceled & !predicted_canc) /
      sum(!df_test$is_canceled)
  )
}

accuracy = function(predicted_canc) {
  (
  sum(df_test$is_canceled & predicted_canc) + 
    sum(!df_test$is_canceled & !predicted_canc)
  ) / nrow(df_test)
}

metrics_table = tribble(
  ~Model, ~Sensitivity, ~Specificity, ~Accuracy,
  1, sensitivity(df_test$predicted_canc1), specificity(df_test$predicted_canc1), accuracy(df_test$predicted_canc1),
  2, k_df$sens[[11]], k_df$spec[[11]], k_df$acc[[11]]
) %>% mutate(Model=as.integer(Model))

to_print1 = metrics_table %>% 
  xtable(align="ccccc")
print(to_print1, 
      "html", 
      include.rownames=F,
      html.table.attributes="align='center',
                             rules='rows',
                             width=50%,
                             frame='hsides',
                             border-spacing=5px"
)
```

```{r, include=F}
detach("package:MASS", unload = TRUE)
```

```{r, include=F}
standardize = function(vector) {
  z = (vector-mean(vector))/sd(vector)
  return(z)
}

#divides correct prediction by total predictions
accuracy = function(x) {
  sum(diag(x)/(sum(rowSums(x))))
}
```

```{r, eval=F, include=F}
#Created k_df file, so we no longer need to run this code. Storing it here with eval=F.
set.seed(216)
ran = sample(1:nrow(df), 0.8 * nrow(df))
df_hotel_binary = df %>% mutate(hotel = ifelse(hotel == "Resort Hotel", 1, 0))
df_norm = as.data.frame(lapply(df_hotel_binary[, c("previous_cancellations", "previous_bookings_not_canceled", "lead_time", "adr", "hotel")], standardize)) 
#subset = df[sample(x=nrow(df), size=10000), ]
df_train = df_norm[ran, ] #%>% cbind(., )
df_test = df_norm[-ran, ]
df_target_category = df[ran, "is_canceled"] %>% pull(is_canceled)
df_test_category = df[-ran, "is_canceled"] %>% pull(is_canceled)
acc = vector("double", 100)
sens = vector("double", 100)
spec = vector("double", 100)
options(width = 80)
for (k in 1:100){
  knn_output = knn(df_train, df_test, cl=df_target_category, k=k)
  confusion_matrix = table(knn_output, df_test_category)
  acc[[k]]= accuracy(confusion_matrix)
  sens[[k]]= confusion_matrix[2,2] / sum(confusion_matrix[,2])
  spec[[k]]= confusion_matrix[1,1] / sum(confusion_matrix[,1])
}
k = as.integer(1:100)
k_df = data.frame(
  k,
  acc,
  sens,
  spec
)
```

# Next Steps:

-Incorporate RF model into ModelPerformance, and Model selection?

- ?Calculate F1 score for both Logistic Regression and KNN + Visualize

- Make a RF model w/ accomopanying metrics